\chapter{Verification and Validation}

This chapter describes the testing methodology adopted to ensure the reliability and accuracy of the developed system. It covers the testing paradigm, the scope of test cases, a detailed analysis of encountered software defects, and the final experimental results.

\section{Testing Paradigm}
To ensure a structured approach to verification, the **V-Model** (Verification and Validation Model) was adopted. This model emphasizes the relationship between the design phase and the testing phase. The testing process was divided into three distinct levels:

\begin{enumerate}
    \item \textbf{Unit Testing:} Individual components were tested in isolation. For the Python server, this involved testing the vector calculation functions (e.g., \texttt{find\_ghost\_ball\_position}) and the impact force formula ($F=ma$) with known static values to ensure mathematical correctness.
    \item \textbf{Integration Testing:} This phase focused on the communication between the Android Client and the PC Server. Key tests included verifying the TCP handshake, the serialization of sensor data into JSON format, and the handling of network latency.
    \item \textbf{System Testing:} The full system was validated in a real-world environment. This involved a player performing actual shots while the system tracked the game state and visualized the analytics in real-time.
\end{enumerate}

\section{Testing Scope and Test Cases}
The testing scope covered both the functional requirements (correct physics calculations, accurate object detection) and non-functional requirements (performance, latency). Table~\ref{tab:test_cases} summarizes the key test scenarios.

\begin{table}[h!]
\centering
\caption{Summary of Key Test Cases.}
\label{tab:test_cases}
\begin{tabular}{|l|p{6cm}|p{5cm}|l|}
\hline
\textbf{ID} & \textbf{Test Scenario} & \textbf{Expected Result} & \textbf{Status} \\ \hline
TC-01 & JSON Packet Transmission & Server receives valid JSON structure without corruption. & Passed \\ \hline
TC-02 & Ghost Ball Projection & Projector line intersects the target ball center. & Passed \\ \hline
TC-03 & High-Velocity Shot Detection & Accelerometer detects peak $>$ 20 m/s$^2$. & Passed \\ \hline
TC-04 & Multi-ball Occlusion & System maintains ID of balls when partially obscured. & Partial \\ \hline
\end{tabular}
\end{table}

\section{Detected and Fixed Bugs}
During the implementation and testing phases, several critical software defects were identified. Below is a description of the most significant bugs and the solutions applied.

\subsection{Android UI Thread Blocking (UI Lag)}
\textbf{Problem:} The initial version of the Android application exhibited severe interface lag and unresponsiveness during data recording. The accelerometer sensor was configured to \texttt{SENSOR\_DELAY\_FASTEST}, generating events at approximately 100Hz. The application attempted to update the on-screen \texttt{TextView} elements inside every sensor callback. Since the UI rendering thread operates at a lower frequency (approx. 60Hz), the event queue became overwhelmed, causing the displayed values to "trail" behind reality (e.g., the value would continue rising long after the phone had stopped moving).

\textbf{Solution:} The implementation was modified to decouple data collection from UI updates. A throttling mechanism was introduced to update the UI elements only once every 100ms (10Hz), while the data transmission to the server continued at the full 100Hz rate using a background thread.

\subsection{TCP Stream Fragmentation}
\textbf{Problem:} Occasionally, the Python server would crash with a \texttt{JSONDecodeError}. This occurred because TCP is a stream-oriented protocol, not a message-oriented one. At high transmission rates, multiple JSON objects were coalesced into a single buffer read, or a single JSON object was split across two reads.

\textbf{Solution:} A delimiter (newline character \texttt{\textbackslash n}) was appended to every message sent from Android. On the server side, a buffer was implemented to accumulate incoming bytes until a full delimiter was found, ensuring that only complete JSON strings were passed to the parser.

\subsection{Ghost Ball Jitter}
\textbf{Problem:} The detected position of the cue ball and cue tip fluctuated slightly (by 1-2 pixels) due to sensor noise in the camera, even when the objects were stationary. This caused the projected "Ghost Ball" vector to shake rapidly, making it difficult for the user to aim.

\textbf{Solution:} A moving average filter (size $N=5$) was applied to the coordinates of the detected objects. This smoothed out the high-frequency noise while maintaining acceptable responsiveness to intentional movements.

\section{Experimental Results}
To validate the practical utility of the system, an experiment was conducted to verify the consistency and distinctiveness of the impact force estimation algorithm. Since measuring the absolute force in Newtons without specialized laboratory equipment (e.g., force plates) is difficult, the experiment focused on the \textbf{relative consistency} of the measurements.

\subsection{Force Estimation Consistency}
The test procedure involved performing three series of 10 shots each (30 shots total), categorized by subjective intensity:
\begin{enumerate}
    \item \textbf{Soft shots:} Gentle taps, intended for precise positioning.
    \item \textbf{Medium shots:} Standard shots used during regular gameplay.
    \item \textbf{Hard shots:} Break-type shots or power shots.
\end{enumerate}

The data was logged automatically to a CSV file by the system. Table~\ref{tab:raw_data} presents the raw force values recorded for each attempt.

\begin{table}[h!]
\centering
\caption{Raw recorded force values (in Newtons) for 30 experimental shots.}
\label{tab:raw_data}
\begin{tabular}{crrr}
\toprule
\textbf{Attempt \#} & \textbf{Soft (N)} & \textbf{Medium (N)} & \textbf{Hard (N)} \\
\midrule
1  & 48.5 & 115.2 & 205.4 \\
2  & 52.1 & 122.8 & 218.1 \\
3  & 45.0 & 130.5 & 230.2 \\
4  & 60.3 & 118.4 & 198.7 \\
5  & 55.8 & 140.1 & 240.5 \\
6  & 62.4 & 125.6 & 222.9 \\
7  & 58.1 & 135.2 & 210.3 \\
8  & 49.9 & 128.9 & 225.8 \\
9  & 53.2 & 112.7 & 218.0 \\
10 & 50.6 & 138.3 & 235.1 \\
\bottomrule
\end{tabular}
\end{table}

Based on the raw data, a statistical analysis was performed to calculate the Mean Force ($F_{avg}$) and Standard Deviation ($\sigma$) for each category. The results are summarized in Table~\ref{tab:force_results}.

\begin{table}[h!]
\centering
\caption{Statistical analysis of impact force measurements ($N=30$).}
\label{tab:force_results}
\begin{tabular}{lrrr}
\toprule
\textbf{Shot Category} & \textbf{Min (N)} & \textbf{Max (N)} & \textbf{Mean $\pm$ Std Dev (N)} \\
\midrule
Soft Shot   &  45.0 &  62.4 & \textbf{53.6 $\pm$ 5.4} \\
Medium Shot & 112.7 & 140.1 & \textbf{126.8 $\pm$ 9.1} \\
Hard Shot   & 198.7 & 240.5 & \textbf{220.5 $\pm$ 13.2} \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Interpretation:}
The results demonstrate a clear separation between the categories. As shown in the tables, the highest recorded value for a "Soft" shot (62.4 N) is significantly lower than the lowest value for a "Medium" shot (112.7 N). This lack of overlap confirms that the system effectively distinguishes between different levels of player intent using the accelerometer-based algorithm ($F=ma$).

The standard deviation increases with the force of the shot (from $\pm 5.4$N to $\pm 13.2$N), which is consistent with the natural biomechanical variability when performing high-velocity movements.

\subsection{System Latency and Performance}
A secondary test was conducted to evaluate the real-time capabilities of the system. The total latency was measured as the time difference between the sensor event timestamp (on Android) and the visualization update on the PC.

\begin{itemize}
    \item \textbf{Network Latency:} Average 15ms (local Wi-Fi network).
    \item \textbf{Processing Time:} Average 25ms (Vision Module inference per frame).
    \item \textbf{Frame Rate:} The vision module maintained a stable 30 FPS on the test workstation.
\end{itemize}

These performance metrics confirm that the system acts in "near real-time," providing feedback instant enough for the user to relate the data to the just-performed action.