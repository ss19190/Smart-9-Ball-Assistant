\chapter{Internal Specification}

This chapter presents the technical details of the solution, including the system architecture, key data structures, and a description of the implementation of the most critical modules in Python and Java.

\section{System Concept}
The system concept is based on the fusion of sensory and visual data to assist in playing billiards. The system consists of:
\begin{enumerate}
    \item \textbf{Vision Module (AI):} Analyzes the camera feed, detects billiard balls and the cue, and subsequently calculates the "Ghost Ball" --- the predicted position of the cue ball at the moment of impact.
    \item \textbf{Telemetry Module:} Analyzes the force of the impact and the smoothness of the player's movement based on IMU sensor data (accelerometer, gyroscope) transmitted via USB cable from a smartphone.
\end{enumerate}

\section{System Architecture}
The system operates on a client-server architecture. The smartphone (Client) collects data and transmits it via TCP to the workstation (Server), which processes the camera image in parallel.

\begin{figure}[htbp]
    \centering
    % Ensure the path exists or remove the line below to compile without the image
    \includegraphics[width=0.9\textwidth]{./graf/arch.png}
    \caption{System Architecture Diagram and logic flow.}
    \label{fig:sys_arch}
\end{figure}

The main unit (PC) runs two independent processes (Python scripts):
\begin{itemize}
    \item \textbf{Vision Process (\texttt{bilard.py}):} Utilizes the \texttt{inference} and \texttt{supervision} libraries for object detection and vector calculations.
    \item \textbf{Sensor Server (\texttt{sensors.py}):} A multi-threaded TCP server that receives JSON data, parses it, and visualizes graphs using the \texttt{OpenCV} library.
\end{itemize}

\section{Description of Data Structures}

\subsection{Network Payload (JSON)}
Communication between the Android device and the PC is handled using the JSON format. A main feature is the transmission of linear acceleration (gravity excluded) and angular velocity.

\begin{figure}[htbp]
\centering
\begin{lstlisting}[
    language=Java,
    basicstyle=\ttfamily\small,
    breaklines=true,
    captionpos=b
]
// JSON format generated in MainActivity.java
String json = String.format(Locale.US,
    "{\"acc_x\": %.4f, \"acc_y\": %.4f, \"acc_z\": %.4f, " +
    "\"gyro_x\": %.4f, \"gyro_y\": %.4f, \"gyro_z\": %.4f}",
    ax, ay, az, gx, gy, gz);
\end{lstlisting}
\caption{JSON structure creation in Java (Android).}
\label{fig:code:json_payload}
\end{figure}

\subsection{Physics Vectors (Python)}
The vision module operates on vectors from the \texttt{NumPy} library to compute trajectories.

\begin{lstlisting}[
    language=Python,
    basicstyle=\ttfamily\small,
    breaklines=true
]
# Position representation in bilard.py
cue_ball_center = np.array([x, y], dtype=np.float32)
aim_vector = normalize_vector(tip_pos - handle_pos)
\end{lstlisting}

\section{Components and Modules}

\subsection{Mobile Module (Android)}
The mobile application was developed in Java. The key component is the \texttt{SensorManager}. The \texttt{TYPE\_LINEAR\_ACCELERATION} sensor was utilized instead of the standard accelerometer to eliminate the influence of gravity on the impact force measurement.

\begin{lstlisting}[
    language=Java,
    basicstyle=\ttfamily\small,
    breaklines=true
]
// MainActivity.java - sensor initialization
linearAcceleration = sensorManager.getDefaultSensor(
    Sensor.TYPE_LINEAR_ACCELERATION
);
\end{lstlisting}

\subsection{Vision Module (Computer Vision)}
This module utilizes two separate neural network models hosted on the Roboflow platform, optimized for instant inference:

\begin{itemize}
    \item \textbf{Ball Detection:} A generic object detection model (version \texttt{ball-detection-bzirz/3}) based on the state-of-the-art \textbf{YOLOv12} \cite{bib:yolo12} architecture. It is trained to localize billiard balls and classifies objects into two distinct classes: \texttt{cue ball} and \texttt{other}. The model works on a standard input resolution ($640 \times 640$) and outputs bounding box coordinates.
    \item \textbf{Cue Detection:} A pose estimation model (version \texttt{cue-detection-ciazj/3}) utilizing the \textbf{YOLOv8-pose} \cite{bib:yolov8-ultralytics} architecture. Unlike the ball detector, this model outputs semantic keypoints representing the \texttt{tip} and \texttt{handle}, necessary for calculating the aiming vector.
\end{itemize}

\section{Overview of Key Algorithms}

\subsection{Ghost Ball Algorithm}
The implementation translates the vector mathematics and geometric rules defined in Section 2.3.1 into Python code using the \texttt{NumPy} library. The function \texttt{find\_ghost\_ball\_position} calculates the projection vector and validates the perpendicular distance to render the visual aid.

\begin{figure}[H]
\centering
\begin{lstlisting}[
    language=Python,
    basicstyle=\ttfamily\footnotesize,
    breaklines=true,
    captionpos=b
]
def find_ghost_ball_position(cue_ball_pos, aim_vector, target_ball_pos):
    vec_to_target = target_ball_pos - cue_ball_pos
    projection_length = np.dot(vec_to_target, aim_vector)
    
    # Calculating the closest point on the shot line
    closest_point = cue_ball_pos + aim_vector * projection_length
    perp_dist = np.linalg.norm(target_ball_pos - closest_point)
    
    # Correction for ball radius (backward offset)
    if perp_dist < BALL_DIAMETER_PX:
        back_offset = math.sqrt(BALL_DIAMETER_PX**2 - perp_dist**2)
        dist_impact = projection_length - back_offset
        return cue_ball_pos + aim_vector * dist_impact
\end{lstlisting}
\caption{Vector-based Ghost Ball calculation implementation.}
\label{fig:code:ghost_ball}
\end{figure}

\subsection{Impact Force Calculation (Physics)}
The \texttt{sensors.py} module implements the force estimation model derived in Section 2.3.2. To ensure flexibility, the system does not use hard-coded anthropometric constants in the source code. Instead, it dynamically loads the user's attributes (weight and gender) from a \texttt{config.json} file.

Based on these attributes, the system selects the appropriate effective mass coefficient ($\mu_{gender}$) --- as detailed in the theoretical analysis (see Section 2.3.2) --- and computes the personalized arm mass ($m_{arm}$). The final impact force is then derived by applying the calculated mass to the linear acceleration vector received from the mobile device.

Additionally, the algorithm implements a peak detection logic (refer to Section 2.4.2) that specifically identifies the \textit{second} significant peak in the signal buffer. This implementation detail allows the system to distinguish the actual forward strike from the preparatory backswing movement.
\section{Implementation Details}

\subsection{Thread Synchronization (Python)}
The TCP server in \texttt{sensors.py} operates in a separate thread (\texttt{daemon=True}) to avoid blocking the interface drawing loop (GUI) in the OpenCV library, if someone would like to run both moduls at the same time.

\begin{lstlisting}[
    language=Python,
    basicstyle=\ttfamily\small,
    breaklines=true
]
# sensors.py - Threading implementation
threading.Thread(target=tcp_server_thread, daemon=True).start()

while True:
    # Main GUI Loop (OpenCV)
    cv2.imshow("Hit Analysis", window)
    if cv2.waitKey(20) & 0xFF == ord('q'): break
\end{lstlisting}

\subsection{Network Handling (Android)}
In the Android application, a separate thread was employed for network operations to avoid the \texttt{NetworkOnMainThreadException}. Data is transmitted at a frequency of approximately 100Hz (every 10ms), ensuring smooth physics representation.

\section{Applied Design Patterns}
\begin{itemize}
    \item \textbf{Listener Pattern (Android):} The implementation if the \texttt{SensorEventListener} interface enables reactive handling of sensor value changes only when they occur. \cite{bib:patterns}
    \item \textbf{Producer-Consumer:} The TCP thread (Producer) receives data and updates the global \texttt{sensor\_data} structure, which is subsequently consumed by the main visualization loop.\cite{bib:patterns}
\end{itemize}
